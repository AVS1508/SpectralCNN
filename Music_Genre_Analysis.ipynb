{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"g12QuUf5Yu2Y","executionInfo":{"status":"error","timestamp":1701978035008,"user_tz":300,"elapsed":30671,"user":{"displayName":"Aditya Vikram Singh","userId":"11030669023296652655"}},"outputId":"7d1f3f51-c50f-46d6-86b2-7b45275d33fb","colab":{"base_uri":"https://localhost:8080/","height":399}},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-859cd1129ce7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive to the Colab VM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mFOLDERNAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"COMPSCI 682/compsci-682-project\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Mount Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","FOLDERNAME = \"COMPSCI 682/compsci-682-project\"\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","# %cd /content/drive/My\\ Drive/$FOLDERNAME/datasets\n","# !wget https://raw.githubusercontent.com/coreyker/dnn-mgr/master/gtzan/train_filtered.txt\n","# !wget https://raw.githubusercontent.com/coreyker/dnn-mgr/master/gtzan/valid_filtered.txt\n","# !wget https://raw.githubusercontent.com/coreyker/dnn-mgr/master/gtzan/test_filtered.txt\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtyD38uKZXOC"},"outputs":[],"source":["# Setting up locale\n","import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUUyQMoJVtDU"},"outputs":[],"source":["from src.configuration import *\n","from src.dataset import *\n","from src.networks import *\n","from src.utils import *\n","import src.preprocess as pp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jS_jcTAhZl9q"},"outputs":[],"source":["# Setting up environment for using GPU or CPU as per availability\n","dtype = torch.float32\n","device = torch.device('cuda') if USE_GPU and torch.cuda.is_available() else torch.device('cpu')\n","print('Using device:', device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ci5VbG-kdVnq"},"outputs":[],"source":["# Preprocess the dataset to extract and save features\n","if pp.are_features_extracted(\"datasets/features\"):\n","    print(\"Features already extracted. Proceed further...\")\n","else:\n","    print(\"Features absent. Processing...\")\n","    pp.generate_spectrograms(\n","        data_path=\"datasets/genres\",\n","        save_path=\"datasets/features\"\n","    )\n","    print(\"Features extracted. Proceed further...\")\n","\n","# Note that one song in GTZAN dataset contains data in unknown/corrupt format: we will delete if this exists.\n","if os.path.exists(\"datasets/genres/jazz/jazz.00054.wav\"):\n","    os.remove(\"datasets/genres/jazz/jazz.00054.wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HC01S6KKZ4gZ"},"outputs":[],"source":["\n","# Log details about the datasets\n","print(\"Number of audio instances: \", len(audio_dataset)) # Expect 999\n","print(\"Number of melspectrogram instances: \", len(melspectrogram_dataset)) # Expect 999\n","print(\"Number of class labels: \", len(CLASS_LABELS)) # Expect 10\n","print(\"Class labels: \", CLASS_LABELS)"]},{"cell_type":"markdown","metadata":{"id":"MLoZ3p_Lp0Sj"},"source":["# What does this mean? $661794 \\approx 30 \\cdot 22050$ (seconds * sample rate (bitrate))\n","\n","# What does each number in the tensor mean?\n","The numbers in a PyTorch waveform represent the amplitude of the waveform at each point in time. The waveform is a sequence of numbers, where each number represents the amplitude of the waveform at a specific point in time. The waveform is typically used to represent audio signals, but it can also be used to represent other types of signals, such as video signals or sensor data.\n","\n","# What is the minimum-maximum range for each value in the tensor?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqjSixo2mKXi"},"outputs":[],"source":["fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16,8))\n","print_stats(audio_dataset[0])\n","plot_waveform(audio_dataset[0], title=\"Blues-00000 Waveform\", ax=axs[0,0])\n","plot_spectrogram(audio_dataset[0], title=\"Blues-00000 Spectrogram\", ax=axs[0,1])\n","plot_spectrogram(audio_dataset[0],  type=\"melspectrogram\", title=\"Blues-00000 Melspectrogram\",ax=axs[1,0])\n","plot_spectrogram(audio_dataset[0],  type=\"mfcc\", title=\"Blues-00000 MFCC\",ax=axs[1,1])\n","fig.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yYpjr1Ro0N9U"},"outputs":[],"source":["# Melspectrogram\n","random_feature_display(\"melspectrogram\", \"Mel Spectrogram\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDJB0GIl0Nne"},"outputs":[],"source":["# Waveplot\n","random_feature_display(\"waveplot\", \"Waveform Plot\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJdEzBWG0N0N"},"outputs":[],"source":["# Spectrogram\n","random_feature_display(\"spectrogram\", \"Spectrogram\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_jvV-C80OGc"},"outputs":[],"source":["# MFCC\n","random_feature_display(\"mfcc\", \"Mel Frequency Cepstral Coefficients (MFCC)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ly5wSKqrauFB"},"outputs":[],"source":["train_loader = get_dataloader(data_path=\"datasets/\", split='train')\n","iter_train_loader = iter(train_loader)\n","train_wav, train_genre = next(iter_train_loader)\n","\n","valid_loader = get_dataloader(data_path=\"datasets/\", split='valid')\n","test_loader = get_dataloader(data_path=\"datasets/\", split='test')\n","iter_test_loader = iter(test_loader)\n","test_wav, test_genre = next(iter_test_loader)\n","print('training data shape: %s' % str(train_wav.shape))\n","print('validation/test data shape: %s' % str(test_wav.shape))\n","print(train_genre)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OalXFWw5Wcwq"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","cnn = ConvolutionalNeuralNetwork().to(device)\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","valid_losses = []\n","num_epochs = 30\n","\n","for epoch in range(num_epochs):\n","    losses = []\n","\n","    # Train\n","    cnn.train()\n","    for (wav, genre_index) in train_loader:\n","        wav = wav.to(device)\n","        genre_index = genre_index.to(device)\n","\n","        # Forward\n","        out = cnn(wav)\n","        loss = loss_function(out, genre_index)\n","\n","        # Backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss.item())\n","    print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, np.mean(losses)))\n","\n","    # Validation\n","    cnn.eval()\n","    y_true = []\n","    y_pred = []\n","    losses = []\n","    for wav, genre_index in valid_loader:\n","        wav = wav.to(device)\n","        genre_index = genre_index.to(device)\n","\n","        # reshape and aggregate chunk-level predictions\n","        b, c, t = wav.size()\n","        logits = cnn(wav.view(-1, t))\n","        logits = logits.view(b, c, -1).mean(dim=1)\n","        loss = loss_function(logits, genre_index)\n","        losses.append(loss.item())\n","        _, pred = torch.max(logits.data, 1)\n","\n","        # append labels and predictions\n","        y_true.extend(genre_index.tolist())\n","        y_pred.extend(pred.tolist())\n","    accuracy = accuracy_score(y_true, y_pred)\n","    valid_loss = np.mean(losses)\n","    print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n","\n","    # Save model\n","    valid_losses.append(valid_loss.item())\n","    if np.argmin(valid_losses) == epoch:\n","        print('Saving the best model at %d epochs!' % epoch)\n","        torch.save(cnn.state_dict(), 'best_model.ckpt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUk_JVjwdVyD"},"outputs":[],"source":["# Load the best model\n","S = torch.load('best_model.ckpt')\n","cnn.load_state_dict(S)\n","print('loaded!')\n","\n","# Run evaluation\n","cnn.eval()\n","y_true, y_pred = [], []\n","\n","with torch.no_grad():\n","    for wav, genre_index in test_loader:\n","        wav = wav.to(device)\n","        genre_index = genre_index.to(device)\n","\n","        # reshape and aggregate chunk-level predictions\n","        b, c, t = wav.size()\n","        logits = cnn(wav.view(-1, t))\n","        logits = logits.view(b, c, -1).mean(dim=1)\n","        _, pred = torch.max(logits.data, 1)\n","\n","        # append labels and predictions\n","        y_true.extend(genre_index.tolist())\n","        y_pred.extend(pred.tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDeZB9vueM2V"},"outputs":[],"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","accuracy = accuracy_score(y_true, y_pred)\n","cm = confusion_matrix(y_true, y_pred)\n","sns.heatmap(cm, annot=True, xticklabels=class_labels, yticklabels=class_labels, cmap=\"YlGn\")\n","print('Accuracy: %.4f' % accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TPmsKjIFg2dL"},"outputs":[],"source":["print(cnn)\n","wav, _ = next(iter(train_loader))\n","wav = wav.to(device)\n","yhat = cnn(wav)\n","make_dot(yhat, params=dict(list(cnn.named_parameters()))).render(\"CNN_Model_GTZAN\", format=\"png\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}